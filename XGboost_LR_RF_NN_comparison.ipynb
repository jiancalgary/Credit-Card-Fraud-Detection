{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# Here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use StandardScaler to process the column data\n",
      "Train Test Split ratio is 0.3\n",
      "X_train shape: (199364, 15)\n",
      "y_train shape: (199364,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjian/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/yangjian/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.98      0.90      0.99      0.94      0.89     85296\n",
      "          1       0.06      0.90      0.98      0.12      0.94      0.88       147\n",
      "\n",
      "avg / total       1.00      0.98      0.90      0.99      0.94      0.89     85443\n",
      "\n",
      "SMOTE Pipeline Score 0.9770490268366046\n",
      "SMOTE AUC score:  0.9797647041371416\n",
      "SMOTE F1 Score:  0.11944319712617871\n",
      "Use StandardScaler to process the column data\n",
      "Train Test Split ratio is 0.3\n",
      "X_train shape: (199364, 15)\n",
      "y_train shape: (199364,)\n",
      "Total Time is:  0.07780126730600993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "(284807, 31)\n",
    "\n",
    "1. ----\n",
    "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
    "       'Class'],\n",
    "      dtype='object')\n",
    "\n",
    "2. ----\n",
    "All columns are float except the 'class' which is 0/1 int\n",
    "\n",
    "3. ----\n",
    "No Missing Value\n",
    "\n",
    "4. ----\n",
    "print(df['Class'].value_counts())\n",
    "print(df['Class'].value_counts()[0]/len(df['Class']) * 100)\n",
    "print(df['Class'].value_counts()[1]/len(df['Class']) * 100)\n",
    "0    284315\n",
    "1       492\n",
    "Name: Class, dtype: int64\n",
    "99.82725143693798\n",
    "0.1727485630620034\n",
    "\"\"\"\n",
    "\n",
    "def data_processor():\n",
    "    df = pd.read_csv('creditcard.csv')\n",
    "    df = df.drop('Time', axis=1)\n",
    "    features_to_select = ['V14', 'V4', 'V17', 'V10', 'V12', 'V20', 'Amount', 'V21', 'V26', 'V28', 'V11', 'V19', 'V8', 'V7', 'V13']\n",
    "\n",
    "    print('Use StandardScaler to process the column data')\n",
    "    scaler = StandardScaler()\n",
    "    df[df.columns[:-1].tolist()] = scaler.fit_transform(df[df.columns[:-1].tolist()])\n",
    "    # print(df.head(5))\n",
    "    X = df[df.columns[:-1].tolist()]#select all the factors except target variable, in this case, the target variable is in the lst column\n",
    "    X = X[features_to_select]# select only interested features\n",
    "    y = df[df.columns[-1]]\n",
    "\n",
    "    print(\"Train Test Split ratio is 0.3\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def xgb_classifier(X_train, X_test, y_train, y_test, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    alg = XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                        min_child_weight=3, gamma=0.2, subsample=0.6, colsample_bytree=1.0,\n",
    "                        objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "\n",
    "    if useTrainCV:\n",
    "        print(\"Start Feeding Data\")\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "        # xgtest = xgb.DMatrix(X_test.values, label=y_test.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    \n",
    "    print('Start Training')\n",
    "    alg.fit(X_train, y_train, eval_metric='auc')\n",
    "\n",
    "    # param_test1 = {'max_depth': [2,4,6],\n",
    "    #               'n_estimators': [50,100,200]}\n",
    "    # gsearch1 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "    #                                                 min_child_weight=3, gamma=0.2, subsample=0.8,\n",
    "    #                                                 colsample_bytree=1.0,\n",
    "    #                                                 objective='binary:logistic', nthread=4, scale_pos_weight=1,\n",
    "    #                                                 seed=27),\n",
    "    #                         param_grid=param_test1,\n",
    "    #                         scoring='f1',\n",
    "    #                         n_jobs=4, iid=False, cv=5)\n",
    "    # gsearch1.fit(X_train, y_train)\n",
    "    # print(gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "\n",
    "    # on test dataset\n",
    "    print(\"Start Predicting\")\n",
    "    predictions = alg.predict(X_test)\n",
    "    pred_proba = alg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # evaluation\n",
    "    print(\"\\nabout this model\")\n",
    "    print(\"Accuracy: %.4g\" % metrics.accuracy_score(y_test, predictions))\n",
    "    print(\"AUC : %f\" % metrics.roc_auc_score(y_test, pred_proba))\n",
    "    print(\"F1 Score : %f\" % metrics.f1_score(y_test, predictions))\n",
    "\n",
    "    feat_imp = alg.feature_importances_\n",
    "    feat = X_train.columns.tolist()\n",
    "    # clf.best_estimator_.booster().get_fscore()\n",
    "    res_df = pd.DataFrame({'Features': feat, 'Importance': feat_imp}).sort_values(by='Importance', ascending=False)\n",
    "    res_df.plot('Features', 'Importance', kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    plt.show()\n",
    "    print(res_df)\n",
    "    print(res_df[\"Features\"].tolist())\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance\n",
    "\n",
    "#perm = PermutationImportance(alg, random_state=1).fit(X_test, y_test)\n",
    "#eli5.show_weights(perm, feature_names = X_test.columns.tolist())\n",
    "\n",
    "def logistic_regression():\n",
    "    \"\"\"\n",
    "    F1 score is: 0.7285714285714285\n",
    "    AUC Score is: 0.9667565771367231\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = data_processor()\n",
    "    clf = LogisticRegression(C=1e5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Score: \", clf.score(X_test, y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    print(\"F1 score is: {}\".format(f1_score(y_test, y_pred)))\n",
    "    print(\"AUC Score is: {}\".format(roc_auc_score(y_test, y_pred_proba)))\n",
    "    \n",
    "    print(classification_report(y_test,y_pred))\n",
    "   \n",
    "\n",
    "\n",
    "def logistic_with_smote():\n",
    "    X_train, X_test, y_train, y_test = data_processor()\n",
    "\n",
    "    clf = LogisticRegression(C=1e5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # build model with SMOTE imblearn\n",
    "    smote_pipeline = make_pipeline_imb(SMOTE(random_state=4), clf)\n",
    "\n",
    "    smote_model = smote_pipeline.fit(X_train, y_train)\n",
    "    smote_prediction = smote_model.predict(X_test)\n",
    "    smote_prediction_proba = smote_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(classification_report_imbalanced(y_test, smote_prediction))\n",
    "    print('SMOTE Pipeline Score {}'.format(smote_pipeline.score(X_test, y_test)))\n",
    "    print(\"SMOTE AUC score: \", roc_auc_score(y_test, smote_prediction_proba))\n",
    "    print(\"SMOTE F1 Score: \", f1_score(y_test, smote_prediction))\n",
    "\n",
    "\n",
    "def randomForest():\n",
    "    \"\"\"\n",
    "    F1 score is: 0.7857142857142857\n",
    "    AUC Score is: 0.9450972761670293\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = data_processor()\n",
    "    # parameters = {'n_estimators': [10, 20, 30, 50], 'max_depth': [2, 3, 4]}\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=4, n_estimators=20)\n",
    "    # clf = GridSearchCV(alg, parameters, n_jobs=4)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Score: \", clf.score(X_test, y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"F1 score is: {}\".format(f1_score(y_test, y_pred)))\n",
    "    print(\"AUC Score is: {}\".format(roc_auc_score(y_test, y_pred_proba)))\n",
    "\n",
    "    # print(\"The Features Importance are: \")  # for feature, value in zip(X_train.columns, clf.feature_importances_):\n",
    "    #     print(feature, value)\n",
    "    # print(clf.best_estimator_)\n",
    "    # print(clf.best_params_)\n",
    "    # print(clf.best_score_)\n",
    "\n",
    "\n",
    "def neural_nets():\n",
    "    \"\"\"\n",
    "    Score:  0.9994148145547324\n",
    "    F1 score is: 0.822695035460993\n",
    "    AUC Score is: 0.9608730286337007\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = data_processor()\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100, 100, 100,))\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Score: \", clf.score(X_test, y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    print(\"F1 score is: {}\".format(f1_score(y_test, y_pred)))\n",
    "    print(\"AUC Score is: {}\".format(roc_auc_score(y_test, y_pred_proba)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # logistic_regression()\n",
    "    # randomForest()\n",
    "    logistic_with_smote()\n",
    "    # neural_nets()\n",
    "    start = time.time()\n",
    "    X_train, X_test, y_train, y_test = data_processor()\n",
    "    #xgb_classifier(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print(\"Total Time is: \", (time.time() - start)/60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
